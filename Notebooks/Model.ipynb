{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7644be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca0acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df=pd.read_csv('../Dataset/Processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77a4982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Electricity_Consumed', 'Temperature', 'Humidity',\n",
       "       'Wind_Speed', 'Anomaly_Label', 'Avg_of_past12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d138fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "Anomaly_Label\n",
      "0    4750\n",
      "1     250\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE:\n",
      "Anomaly_Label\n",
      "0    4750\n",
      "1    4750\n",
      "Name: count, dtype: int64\n",
      "Model and scaler saved successfully!\n",
      "\n",
      "Confusion Matrix:\n",
      "[[923  44]\n",
      " [ 15 918]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       967\n",
      "           1       0.95      0.98      0.97       933\n",
      "\n",
      "    accuracy                           0.97      1900\n",
      "   macro avg       0.97      0.97      0.97      1900\n",
      "weighted avg       0.97      0.97      0.97      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Prepare features (X) and target (y) ---\n",
    "# Drop the 'Timestamp' column and target label for training\n",
    "X = df.drop([\"Anomaly_Label\", \"Timestamp\"], axis=1)\n",
    "y = df[\"Anomaly_Label\"]\n",
    "\n",
    "# --- 3. Check the class distribution (imbalance) ---\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# --- 4. Scale features ---\n",
    "# Scaling is important for SMOTE and improves model performance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- 5. Handle class imbalance using SMOTE ---\n",
    "# SMOTE generates synthetic samples for the minority class (anomalies)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_res).value_counts())\n",
    "\n",
    "# --- 6. Split the resampled data into training and testing sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "# --- 7. Initialize and train the Random Forest classifier ---\n",
    "# class_weight='balanced' helps the model handle any remaining imbalance\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- 8. Predict probabilities on the test set ---\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # probability of being anomaly\n",
    "\n",
    "# --- 9. Apply threshold to determine final predictions ---\n",
    "# Default threshold = 0.5; can adjust (e.g., 0.3) to increase anomaly recall\n",
    "threshold = 0.5\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "# --- 10. Save the trained model and scaler for future use ---\n",
    "joblib.dump(model, \"../Models/rf_model.pkl\")\n",
    "joblib.dump(scaler, \"../Models/scaler.pkl\")\n",
    "print(\"Model and scaler saved successfully!\")\n",
    "\n",
    "# --- 11. Evaluate the model ---\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
